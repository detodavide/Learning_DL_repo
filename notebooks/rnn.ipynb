{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "from torch.nn.utils import rnn as rnn_utils\n",
    "from generators.data_generation import generate_sequences\n",
    "from model_managers.DeepLearningManager import DeepLearningManager\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sequence(points, direction):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(3, 2))\n",
    "    \n",
    "    # Plot the sequence of points\n",
    "    point_array = np.array(points)\n",
    "    ax.plot(point_array[:, 0], point_array[:, 1], marker='o', linestyle='-')\n",
    "    \n",
    "    # Plot direction arrow\n",
    "    if direction == 1:  # Clockwise\n",
    "        start_point = point_array[0]\n",
    "        end_point = point_array[-1]\n",
    "        dx = end_point[0] - start_point[0]\n",
    "        dy = end_point[1] - start_point[1]\n",
    "        ax.arrow(start_point[0], start_point[1], dx, dy, head_width=0.1, head_length=0.1, fc='k', ec='k')\n",
    "    elif direction == 0:  # Counterclockwise\n",
    "        start_point = point_array[-1]\n",
    "        end_point = point_array[0]\n",
    "        dx = end_point[0] - start_point[0]\n",
    "        dy = end_point[1] - start_point[1]\n",
    "        ax.arrow(start_point[0], start_point[1], dx, dy, head_width=0.1, head_length=0.1, fc='k', ec='k')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title('Sequence of Points with Direction')\n",
    "    \n",
    "    # Show plot\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, directions = generate_sequences(n=128, seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(3):\n",
    "    plot_sequence(points[i], directions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "n_hidden_dim = 2\n",
    "\n",
    "torch.manual_seed(101)\n",
    "rnn_cell = nn.RNNCell(input_size=n_features, hidden_size=n_hidden_dim)\n",
    "rnn_state = rnn_cell.state_dict()\n",
    "rnn_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To understand the RNN architecture, we utilize states generated by nn.RNNCell. This allows us to build the architecture from scratch, beginning with linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear layers and get the generated parameters from the RNNCell\n",
    "linear_input = nn.Linear(n_features, n_hidden_dim)\n",
    "linear_hidden = nn.Linear(n_hidden_dim, n_hidden_dim)\n",
    "\n",
    "with torch.no_grad():\n",
    "    linear_input.weight = nn.Parameter(rnn_state['weight_ih'])\n",
    "    linear_input.bias = nn.Parameter(rnn_state['bias_ih'])\n",
    "    linear_hidden.weight = nn.Parameter(rnn_state['weight_hh'])\n",
    "    linear_hidden.bias = nn.Parameter(rnn_state['bias_hh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial hidden state set to 0 with dims 1 x 2\n",
    "initial_hidden = torch.zeros(1, n_hidden_dim)\n",
    "initial_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now generate the first hidden state, this is a simple linear transformation without any activ func\n",
    "th = linear_hidden(initial_hidden)\n",
    "th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now take the first sequence with 4 points, 2 x 4\n",
    "X = torch.as_tensor(points[0]).float()\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = linear_input(X[0:1])\n",
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the linear transformations to replicate the RNN\n",
    "adds = th + tx\n",
    "# Then use the tanh activation function\n",
    "torch.tanh(adds)\n",
    "\n",
    "# What we get is the updated hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single layer RNN\n",
    "n_features = 2\n",
    "n_hidden_dim = 2\n",
    "\n",
    "torch.manual_seed(101)\n",
    "rnn_cell = nn.RNN(input_size=n_features, hidden_size=n_hidden_dim)\n",
    "rnn_state = rnn_cell.state_dict()\n",
    "\n",
    "# As you can see we have l0 added to the weights and biases that indicates the layer 0\n",
    "rnn_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Input Dimension\n",
    "In PyTorch, if you set the batch_first argument to True when using the nn.RNN class, it adjusts the expected input tensor layout to have the batch dimension first. Therefore, if batch_first is set to True, the input tensor should have dimensions (batch_size, sequence_length, input_size). This is useful for compatibility with certain data formats or personal preference in organizing data.\n",
    "\n",
    "However, by default, PyTorch's nn.RNN class assumes the sequence dimension comes first. So, if batch_first is not specified or set to False, the input tensor should have dimensions (sequence_length, batch_size, input_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.as_tensor(points[:3]).float()\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from B S F -> S B F\n",
    "permuted_batch = batch.permute(1,0,2)\n",
    "\n",
    "# RNN friendly dimensions: Sequence - batch - Features\n",
    "permuted_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch second\n",
    "torch.manual_seed(101)\n",
    "rnn = nn.RNN(input_size=n_features, hidden_size=n_hidden_dim)\n",
    "out, final_hidden = rnn(permuted_batch)\n",
    "out.shape, final_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use batch_first argument\n",
    "torch.manual_seed(101)\n",
    "rnn = nn.RNN(input_size=n_features, batch_first=True ,hidden_size=n_hidden_dim)\n",
    "out, final_hidden = rnn(batch)\n",
    "out.shape, final_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember that Datasets and Dataloaders have batch_number as first dimension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Layers stacked\n",
    "torch.manual_seed(101)\n",
    "rnn_stacked = nn.RNN(input_size=2, hidden_size=2, batch_first=True, num_layers=2)\n",
    "rnn_stacked_state = rnn_stacked.state_dict()\n",
    "rnn_stacked_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Bidirectional\n",
    "torch.manual_seed(101)\n",
    "rnn_bidirect = nn.RNN(input_size=2, hidden_size=2, batch_first=True, bidirectional=True)\n",
    "state = rnn_bidirect.state_dict()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forward RNN and backward RNN and pass the parameters to the models\n",
    "torch.manual_seed(19)\n",
    "forward_rnn = nn.RNN(input_size=2, hidden_size=2, batch_first=True)\n",
    "backward_rnn = nn.RNN(input_size=2, hidden_size=2, batch_first=True)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k[:-8], v) for k, v in list(state.items())[4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_rnn.load_state_dict(dict(list(state.items())[:4]))\n",
    "backward_rnn.load_state_dict(dict([(k[:-8], v) for k, v in list(state.items())[4:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the state dictionary into a list of key-value pairs and start from the fifth element\n",
    "state_items = list(state.items())[4:]\n",
    "\n",
    "# Initialize an empty dictionary to store the modified key-value pairs\n",
    "modified_state_dict = {}\n",
    "\n",
    "# Iterate over the key-value pairs obtained from the state dictionary\n",
    "for key, value in state_items:\n",
    "    # Modify the key to remove the '_reverse' suffix, assuming it's present\n",
    "    modified_key = key[:-8]  # Remove the last 8 characters from the key\n",
    "    # Add the modified key-value pair to the modified state dictionary\n",
    "    modified_state_dict[modified_key] = value\n",
    "\n",
    "# Convert the list of modified key-value pairs back into a dictionary\n",
    "modified_state_dict = dict(modified_state_dict)\n",
    "\n",
    "# Load the modified state dictionary into the backward RNN model\n",
    "backward_rnn.load_state_dict(modified_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(1,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the sequence input to the backward_rnn\n",
    "x_rev = torch.flip(X, dims=[1])\n",
    "x_rev, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, h = forward_rnn(X)\n",
    "out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rev, h_rev = backward_rnn(x_rev)\n",
    "out_rev, h_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([out, out_rev], dim=2), torch.cat([h, h_rev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_bidirect(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points, test_directions = generate_sequences(seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "train_data = TensorDataset(torch.as_tensor(points).float(),\n",
    "                           torch.as_tensor(directions).view(-1,1).float())\n",
    "test_data = TensorDataset(torch.as_tensor(test_points).float(),\n",
    "                           torch.as_tensor(test_directions).view(-1,1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SimpleRNN import SquareModel, SquareModelGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SquareModel(n_features=2, hidden_dim=2, n_outputs=1)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager = DeepLearningManager(model, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_manager.set_data_loaders(train_loader=train_loader, val_loader=test_loader)\n",
    "# model_manager.train(n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = model_manager.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_manager.loader_apply(test_loader, model_manager.correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Journey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why GRU?\n",
    "GRU, short for Gated Recurrent Unit, addresses a fundamental challenge encountered in simple RNNs: their inability to effectively manage the flow of information from previous hidden states and current inputs. In traditional RNNs, this lack of control often leads to difficulties in retaining relevant information over long sequences, hindering performance in tasks such as sequence prediction and language modeling.\n",
    "\n",
    "GRU tackles this issue by introducing \"gates\" into the network architecture. These gates, governed by sigmoid functions, enable precise control over the flow of information within the hidden state computation process. Specifically, GRUs employ two key gates: the update gate and the reset gate.\n",
    "\n",
    "The update gate regulates the extent to which information from previous time steps should be retained or updated in the current hidden state.\n",
    "The reset gate determines the degree to which past information should be forgotten or reset, allowing the model to adapt dynamically to changing input patterns.\n",
    "\n",
    "By incorporating these gating mechanisms, GRU architectures empower neural networks to selectively process and retain relevant information, thereby mitigating the vanishing gradient problem and enhancing the model's ability to capture long-range dependencies in sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_cell = nn.GRUCell(input_size=2, hidden_size=2)\n",
    "gru_state = gru_cell.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights and biases represent the 2 gates and the candidate hidden state parameters. The state_dict() method show us the parameters concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get each parameter\n",
    "wx, bx = gru_state['weight_ih'], gru_state['bias_ih']\n",
    "wh, bh = gru_state['weight_hh'], gru_state['bias_hh']\n",
    "wxr, wxz, wxn = wx.split(2, dim=0)\n",
    "whr, whz, whn = wh.split(2, dim=0)\n",
    "bxr, bxz, bxn = bx.split(2, dim=0)\n",
    "bhr, bhz, bhn = bh.split(2, dim=0)\n",
    "\n",
    "print(\"Weight matrices for input-to-hidden connections:\")\n",
    "print(\"wxr:\", wxr)\n",
    "print(\"wxz:\", wxz)\n",
    "print(\"wxn:\", wxn)\n",
    "\n",
    "print(\"\\nWeight matrices for hidden-to-hidden connections:\")\n",
    "print(\"whr:\", whr)\n",
    "print(\"whz:\", whz)\n",
    "print(\"whn:\", whn)\n",
    "\n",
    "print(\"\\nBiases for input-to-hidden connections:\")\n",
    "print(\"bxr:\", bxr)\n",
    "print(\"bxz:\", bxz)\n",
    "print(\"bxn:\", bxn)\n",
    "\n",
    "print(\"\\nBiases for hidden-to-hidden connections:\")\n",
    "print(\"bhr:\", bhr)\n",
    "print(\"bhz:\", bhz)\n",
    "print(\"bhn:\", bhn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary distinction between a simple RNN and a GRU cell lies in the presence of an additional state in the LSTM called the cell state. This cell state is crucial in retaining sequential information over extended distances.\n",
    "\n",
    "In a simple RNN, the network's hidden state is responsible for capturing and propagating information across time steps. However, as sequences grow longer, simple RNNs struggle to maintain relevant information over distant past states due to issues like vanishing gradients.\n",
    "\n",
    "LSTMs address this limitation by introducing a separate cell state alongside the hidden state. This cell state serves as a conveyor belt for preserving crucial information across multiple time steps. By selectively updating, forgetting, and outputting information through specialized gating mechanisms, LSTMs can effectively capture and retain long-term dependencies in sequential data.\n",
    "\n",
    "In summary, while both GRUs and LSTMs utilize gating mechanisms to regulate information flow, LSTMs further augment their capacity for modeling long-range dependencies by incorporating an additional cell state, enabling them to excel in tasks that require retaining context over extended sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell = nn.LSTMCell(input_size=2, hidden_size=2)\n",
    "lstm_state = lstm_cell.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting parameters\n",
    "wx, bx = lstm_state['weight_ih'], lstm_state['bias_ih']\n",
    "wh, bh = lstm_state['weight_hh'], lstm_state['bias_hh']\n",
    "\n",
    "wxi, wxf, wxg, wxo = wx.chunk(4, dim=0)\n",
    "whi, whf, whg, who = wh.chunk(4, dim=0)\n",
    "bxi, bxf, bxg, bxo = bx.chunk(4, dim=0)\n",
    "bhi, bhf, bhg, bho = bh.chunk(4, dim=0)\n",
    "\n",
    "print(\"Weight matrices for input-to-hidden connections:\")\n",
    "print(\"wxi:\", wxi)\n",
    "print(\"wxf:\", wxf)\n",
    "print(\"wxg:\", wxg)\n",
    "print(\"wxo:\", wxo)\n",
    "\n",
    "print(\"\\nWeight matrices for hidden-to-hidden connections:\")\n",
    "print(\"whi:\", whi)\n",
    "print(\"whf:\", whf)\n",
    "print(\"whg:\", whg)\n",
    "print(\"who:\", who)\n",
    "\n",
    "print(\"\\nBiases for input-to-hidden connections:\")\n",
    "print(\"bxi:\", bxi)\n",
    "print(\"bxf:\", bxf)\n",
    "print(\"bxg:\", bxg)\n",
    "print(\"bxo:\", bxo)\n",
    "\n",
    "print(\"\\nBiases for hidden-to-hidden connections:\")\n",
    "print(\"bhi:\", bhi)\n",
    "print(\"bhf:\", bhf)\n",
    "print(\"bhg:\", bhg)\n",
    "print(\"bho:\", bho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SimpleRNN import SquareModelLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SquareModelLSTM(n_features=2, hidden_dim=2, n_outputs=1)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager = DeepLearningManager(model, loss, optimizer)\n",
    "model_manager.set_data_loaders(train_loader=train_loader, val_loader=test_loader)\n",
    "model_manager.train(n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = model_manager.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.loader_apply(test_loader, model_manager.correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = torch.tensor([1, 2, 3, 4])\n",
    "seq2 = torch.tensor([5, 6])\n",
    "seq3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "# Create a list of sequences\n",
    "sequences = [seq1, seq2, seq3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed = pack_sequence(sequences=sequences, enforce_sorted=False)\n",
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed.data[[0,3,6,8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time step 1, the data considered consists of the elements from the original sequences that were active (non-padded) at that time step. The number of active sequences at each time step is indicated by the corresponding value in the batch_sizes tensor.\n",
    "\n",
    "In the provided batch_sizes tensor [3, 3, 2, 1], each value represents the number of active sequences at the corresponding time step. Therefore, at time step 1, there are 3 active sequences. The data tensor [1, 7, 5, 2, 8, 6, 3, 9, 4] contains the packed data from all sequences, and the batch sizes tensor indicates how many sequences are active at each time step.\n",
    "\n",
    "So, at time step 1, the data considered would be [1, 7, 5], representing the first elements of the three original sequences in the batch. These values are from the packed data tensor and correspond to the first time step of the sequences before they were padded and packed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a different lenght sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation.sequences.diff_size_sequences import VariableSizeDataset\n",
    "from models.SimpleRNN import SquareModelPacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_points, var_directions = generate_sequences(variable_len=True)\n",
    "var_points[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_var_data = VariableSizeDataset(var_points, var_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_var_loader = DataLoader(\n",
    "    train_var_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=VariableSizeDataset.pack_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(train_var_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SquareModelPacked(n_features=2, hidden_dim=2, n_outputs=1)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = DeepLearningManager(model, loss, optim)\n",
    "mm.set_data_loaders(train_var_loader)\n",
    "mm.train(n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([ 5, 10, 4, 3, 5, 4, 11, 4, 0, 4, 2])\n",
    "size = 5\n",
    "weight = torch.ones(size)*0.2\n",
    "out_tensor = F.conv1d(torch.as_tensor(arr).float().view( 1, 1, -1), weight=weight.view( 1, 1, -1))\n",
    "out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tensor[0][0][0] == sum(arr[:size])*0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 1-D on Multiple Features/Channels\n",
    "Default shape conv1d N, F=C, L \n",
    "\n",
    "N = Number of sequences (batch_size)\n",
    "\n",
    "F = C = Features or Channels\n",
    "\n",
    "L = Sequence length\n",
    "\n",
    "Convolution of a sequence with 2 features and length of 4 and a single filter 2x2.\n",
    "\n",
    "1x2x4 (sequence) * 1x2x2 (filter) = 1x1x3 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_seq = nn.Conv1d(in_channels=2, out_channels=1, kernel_size=2, bias=False)\n",
    "conv_seq.weight, conv_seq.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation\n",
    "\n",
    "Dilated convolutions in 1D convolutional neural networks (Conv1D) expand the receptive field without increasing the number of parameters. By introducing gaps between elements in the convolutional filter, a dilation rate greater than 1 allows the filter to cover more input units per convolution, capturing wider-range features without additional computational cost. For instance, with a dilation rate of 2, the filter skips every other input element, effectively broadening its perspective on the input sequence while maintaining the same computational footprint. This technique is especially valuable in processing time series or sequential data, where understanding broader context or longer-range dependencies is crucial.\n",
    "Dilation take the filter and apply it to the sequence and skip based on dilation number. Dilation = 1 means no skip, must be 2 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dilated = nn.Conv1d(in_channels=2, out_channels=1, kernel_size=2, dilation=2, bias=False)\n",
    "conv_dilated.weight, conv_dilated.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
